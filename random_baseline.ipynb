{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import tqdm\n",
    "import textworld.gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from textworld import EnvInfos\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 games.\n"
     ]
    }
   ],
   "source": [
    "GAMES_PATH = \"sample_games\"  # This assumes `sample_games.zip` was first unzipped.\n",
    "gamefiles = glob(pjoin(GAMES_PATH, \"*.ulx\"))\n",
    "print(\"Found {} games.\".format(len(gamefiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.rng = RandomState(42)\n",
    "        \n",
    "    def act(self, obs, scores, dones, infos):\n",
    "        return [self.rng.choice(admissible_commands) for admissible_commands in infos[\"admissible_commands\"]]\n",
    "    \n",
    "    def reset(self, env):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPISODES = 10\n",
    "BATCH_SIZE = 10\n",
    "gamefile = gamefiles[8]  # Pick a game.\n",
    "\n",
    "requested_infos = EnvInfos(\n",
    "    max_score=True,\n",
    "    has_won=True,\n",
    "    has_lost=True,\n",
    "    admissible_commands=True,\n",
    ")\n",
    "env_id = textworld.gym.register_games([gamefile], requested_infos)\n",
    "env_id = textworld.gym.make_batch(env_id, batch_size=BATCH_SIZE, parallel=True)\n",
    "\n",
    "agent = RandomAgent()\n",
    "env = gym.make(env_id)\n",
    "agent.reset(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.156073331832886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "start_time = time.time()\n",
    "for no_episode in tqdm.tqdm(range(NB_EPISODES)):\n",
    "    obs, infos = env.reset()\n",
    "        \n",
    "    scores = [0] * BATCH_SIZE\n",
    "    dones = [False] * BATCH_SIZE\n",
    "    steps = [0] * BATCH_SIZE\n",
    "    while not all(dones):\n",
    "        steps = [step + int(not done) for step, done in zip(steps, dones)]\n",
    "        commands = agent.act(obs, scores, dones, infos)\n",
    "        obs, scores, dones, infos = env.step(commands)\n",
    "        \n",
    "    # Collect stats\n",
    "    stats[no_episode] = {}\n",
    "    stats[no_episode][\"score\"] = scores\n",
    "    stats[no_episode][\"steps\"] = steps\n",
    "    stats[no_episode][\"has_won\"] = infos[\"has_won\"]\n",
    "    stats[no_episode][\"has_lost\"] = infos[\"has_lost\"]\n",
    "    \n",
    "elapsed = time.time() - start_time\n",
    "env.close()\n",
    "pprint(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Max possible score for the episode\n",
    "pprint(infos[\"max_score\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Max score achieved by the agent\n",
    "pprint(np.max([stats[no_episode][\"score\"] for no_episode in range(NB_EPISODES)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "# Average score per episode\n",
    "pprint(np.sum([stats[no_episode][\"score\"] for no_episode in range(NB_EPISODES)]) / (NB_EPISODES * BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.56\n"
     ]
    }
   ],
   "source": [
    "# Average number of steps per episode\n",
    "pprint(np.sum([stats[no_episode][\"steps\"] for no_episode in range(NB_EPISODES)]) / (NB_EPISODES * BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# The number of episodes won by the agent, out of NB_EPISODES * BATCH_SIZE \n",
    "pprint(np.sum([stats[no_episode][\"has_won\"] for no_episode in range(NB_EPISODES)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
